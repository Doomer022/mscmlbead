{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c269e8e6",
   "metadata": {},
   "source": [
    "# CELL 1 - Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd052f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "CUDA device name: NVIDIA GeForce RTX 3060\n",
      "\n",
      "Downloading Kaggle dataset ID: utkarshsaxenadn/fruits-classification using kagglehub...\n",
      "NOTE: This requires your Kaggle API key (kaggle.json) to be set up in ~/.kaggle/.\n",
      "Download complete.\n",
      "Path to dataset files: C:\\Users\\Bence\\.cache\\kagglehub\\datasets\\utkarshsaxenadn\\fruits-classification\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import optuna\n",
    "import random\n",
    "import kagglehub # Import for the new download method\n",
    "\n",
    "# --- Constants and Setup ---\n",
    "\n",
    "IMAGE_SIZE = 100 \n",
    "BATCH_SIZE = 64\n",
    "RANDOM_SEED = 42\n",
    "NUM_EPOCHS_TUNE = 10 # Fewer epochs for quick HPO search\n",
    "NUM_EPOCHS_FINAL = 50 # Max epochs for final training (with Early Stopping)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# Determine device (CUDA for GPU training)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "if DEVICE.type == 'cuda':\n",
    "    print(f\"CUDA device name: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "\n",
    "# --- Kaggle Download and DATA_DIR Setup ---\n",
    "DATASET_ID = \"utkarshsaxenadn/fruits-classification\"\n",
    "\n",
    "print(f\"\\nDownloading Kaggle dataset ID: {DATASET_ID} using kagglehub...\")\n",
    "print(\"NOTE: This requires your Kaggle API key (kaggle.json) to be set up in ~/.kaggle/.\")\n",
    "\n",
    "try:\n",
    "    # Use kagglehub to download the dataset\n",
    "    path = kagglehub.dataset_download(DATASET_ID)\n",
    "    \n",
    "    # kagglehub returns the path to the root of the extracted dataset files\n",
    "    DATA_DIR = str(path)\n",
    "    \n",
    "    print(\"Download complete.\")\n",
    "    print(f\"Path to dataset files: {DATA_DIR}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Kaggle Download Failed. Error: {e}\")\n",
    "    print(\"Please ensure your Kaggle API key is correctly configured and the kernel is switched.\")\n",
    "    # Fallback path if the download fails for manual placement\n",
    "    DATA_DIR = './fruits-classification' \n",
    "    print(f\"Falling back to assumed manual data path: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79c0c22",
   "metadata": {},
   "source": [
    "# CELL 2 - Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "02e6cca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Classes: 5\n"
     ]
    }
   ],
   "source": [
    "# --- Data Transforms, Normalization, and Features (Data Augmentation) ---\n",
    "\n",
    "# 1. PIL Image Transforms (Augmentation applied before Tensor conversion)\n",
    "pil_transforms = [\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.RandomRotation(15), \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "]\n",
    "\n",
    "# 2. Tensor Conversion\n",
    "tensor_conversion = [\n",
    "    transforms.ToTensor(),\n",
    "]\n",
    "\n",
    "# 3. Tensor Transforms (Augmentation and Normalization applied after Tensor conversion)\n",
    "tensor_transforms = [\n",
    "    # FIX: RandomErasing MUST be after ToTensor()\n",
    "    transforms.RandomErasing(p=0.2, scale=(0.02, 0.1), ratio=(0.3, 3.3)), \n",
    "    # Normalization\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n",
    "]\n",
    "\n",
    "# Training Transforms (All steps)\n",
    "train_transforms = transforms.Compose(pil_transforms + tensor_conversion + tensor_transforms)\n",
    "\n",
    "# Validation/Test Transforms (Only resize, ToTensor, Normalization)\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n",
    "])\n",
    "\n",
    "\n",
    "# --- Adatfolyam (ImageFolder Ã©s DataLoader) ---\n",
    "TRAIN_DIR = DATA_DIR + '\\\\Fruits Classification\\\\train'\n",
    "TEST_DIR = DATA_DIR + '\\\\Fruits Classification\\\\test'\n",
    "\n",
    "train_data = datasets.ImageFolder(TRAIN_DIR, transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(TEST_DIR, transform=test_transforms)\n",
    "\n",
    "# Split training data into training and validation sets (80/20 split)\n",
    "train_size = int(0.8 * len(train_data))\n",
    "val_size = len(train_data) - train_size\n",
    "train_subset, val_subset = torch.utils.data.random_split(train_data, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders (Data Streaming)\n",
    "train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "CLASS_NAMES = train_data.classes\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "print(f\"Number of Classes: {NUM_CLASSES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3384b9",
   "metadata": {},
   "source": [
    "# CELL 3 - CNN Model Buildup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0d8ee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FruitCNN(nn.Module):\n",
    "    def __init__(self, num_conv_layers, filters, dense_units, dropout_rate, num_classes):\n",
    "        super(FruitCNN, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        in_channels = 3 # RGB\n",
    "        \n",
    "        # Convolutional Block (Each block adds Conv + ReLU + MaxPool = 3 layers)\n",
    "        for i in range(num_conv_layers):\n",
    "            out_channels = filters * (2**i)\n",
    "            # Conv2D Layer\n",
    "            layers += [\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.ReLU(),\n",
    "            ]\n",
    "            # MaxPool2D Layer\n",
    "            layers += [\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            ]\n",
    "            in_channels = out_channels\n",
    "            \n",
    "        self.features = nn.Sequential(*layers)\n",
    "        \n",
    "        # Calculate the size of the feature map after convolutional layers\n",
    "        final_dim = IMAGE_SIZE // (2**num_conv_layers)\n",
    "        flattened_size = out_channels * final_dim * final_dim\n",
    "        \n",
    "        # Fully Connected Layers (4 additional hidden/special layers)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            # Dropout Layer (Special Layer/Regularization)\n",
    "            nn.Dropout(dropout_rate), \n",
    "            # Dense Layer\n",
    "            nn.Linear(flattened_size, dense_units),\n",
    "            nn.ReLU(),\n",
    "            # Dropout Layer (Special Layer/Regularization)\n",
    "            nn.Dropout(dropout_rate), \n",
    "            # Output Layer\n",
    "            nn.Linear(dense_units, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157cb67c",
   "metadata": {},
   "source": [
    "# CELL 4 - Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706ed3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-11 22:24:07,689] A new study created in memory with name: no-name-3da1f2db-0c2e-4760-88b3-25481f926e6e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Hyperparameter Optimization (HPO) with Optuna...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bence\\AppData\\Local\\Temp\\ipykernel_11084\\3661422097.py:39: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  hp_learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
      "[W 2025-12-11 22:24:16,614] Trial 0 failed with parameters: {'num_conv_layers': 2, 'filters': 32, 'dense_units': 256, 'dropout_rate': 0.5, 'learning_rate': 0.0010835199591891294} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\mscmlbead\\fruit_venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\Bence\\AppData\\Local\\Temp\\ipykernel_11084\\3661422097.py\", line 54, in objective\n",
      "    train_model_optuna(model, train_loader, val_loader, optimizer, criterion, NUM_EPOCHS_TUNE, DEVICE)\n",
      "    ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Bence\\AppData\\Local\\Temp\\ipykernel_11084\\3661422097.py\", line 6, in train_model_optuna\n",
      "    for inputs, labels in train_loader:\n",
      "                          ^^^^^^^^^^^^\n",
      "  File \"c:\\mscmlbead\\fruit_venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 732, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"c:\\mscmlbead\\fruit_venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 788, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"c:\\mscmlbead\\fruit_venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 50, in fetch\n",
      "    data = self.dataset.__getitems__(possibly_batched_index)\n",
      "  File \"c:\\mscmlbead\\fruit_venv\\Lib\\site-packages\\torch\\utils\\data\\dataset.py\", line 416, in __getitems__\n",
      "    return [self.dataset[self.indices[idx]] for idx in indices]\n",
      "            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\mscmlbead\\fruit_venv\\Lib\\site-packages\\torchvision\\datasets\\folder.py\", line 245, in __getitem__\n",
      "    sample = self.loader(path)\n",
      "  File \"c:\\mscmlbead\\fruit_venv\\Lib\\site-packages\\torchvision\\datasets\\folder.py\", line 284, in default_loader\n",
      "    return pil_loader(path)\n",
      "  File \"c:\\mscmlbead\\fruit_venv\\Lib\\site-packages\\torchvision\\datasets\\folder.py\", line 264, in pil_loader\n",
      "    return img.convert(\"RGB\")\n",
      "           ~~~~~~~~~~~^^^^^^^\n",
      "  File \"c:\\mscmlbead\\fruit_venv\\Lib\\site-packages\\PIL\\Image.py\", line 972, in convert\n",
      "    self.load()\n",
      "    ~~~~~~~~~^^\n",
      "  File \"c:\\mscmlbead\\fruit_venv\\Lib\\site-packages\\PIL\\ImageFile.py\", line 394, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "                  ~~~~~~~~~~~~~~^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-12-11 22:24:16,616] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 62\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting Hyperparameter Optimization (HPO) with Optuna...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     61\u001b[39m study = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[32m     64\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Best Trial Results ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     65\u001b[39m best_trial = study.best_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\mscmlbead\\fruit_venv\\Lib\\site-packages\\optuna\\study\\study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\mscmlbead\\fruit_venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:67\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     80\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\mscmlbead\\fruit_venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:164\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    161\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\mscmlbead\\fruit_venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:262\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    258\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    259\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    261\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\mscmlbead\\fruit_venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:205\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    207\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    208\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 54\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     51\u001b[39m optimizer = optim.Adam(model.parameters(), lr=hp_learning_rate)\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# Training and Evaluation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m \u001b[43mtrain_model_optuna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_EPOCHS_TUNE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m accuracy = evaluate_model_optuna(model, val_loader, DEVICE)\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mtrain_model_optuna\u001b[39m\u001b[34m(model, train_loader, val_loader, optimizer, criterion, epochs, device)\u001b[39m\n\u001b[32m      4\u001b[39m model.train()\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\mscmlbead\\fruit_venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\mscmlbead\\fruit_venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:788\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    787\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    790\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\mscmlbead\\fruit_venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_collation:\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.dataset, \u001b[33m\"\u001b[39m\u001b[33m__getitems__\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__:\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     52\u001b[39m         data = [\u001b[38;5;28mself\u001b[39m.dataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\mscmlbead\\fruit_venv\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:416\u001b[39m, in \u001b[36mSubset.__getitems__\u001b[39m\u001b[34m(self, indices)\u001b[39m\n\u001b[32m    414\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__([\u001b[38;5;28mself\u001b[39m.indices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    415\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\mscmlbead\\fruit_venv\\Lib\\site-packages\\torchvision\\datasets\\folder.py:245\u001b[39m, in \u001b[36mDatasetFolder.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    238\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m    239\u001b[39m \u001b[33;03m    index (int): Index\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    242\u001b[39m \u001b[33;03m    tuple: (sample, target) where target is class_index of the target class.\u001b[39;00m\n\u001b[32m    243\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    244\u001b[39m path, target = \u001b[38;5;28mself\u001b[39m.samples[index]\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m sample = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    247\u001b[39m     sample = \u001b[38;5;28mself\u001b[39m.transform(sample)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\mscmlbead\\fruit_venv\\Lib\\site-packages\\torchvision\\datasets\\folder.py:284\u001b[39m, in \u001b[36mdefault_loader\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    282\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m accimage_loader(path)\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m284\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpil_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\mscmlbead\\fruit_venv\\Lib\\site-packages\\torchvision\\datasets\\folder.py:264\u001b[39m, in \u001b[36mpil_loader\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    263\u001b[39m     img = Image.open(f)\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRGB\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\mscmlbead\\fruit_venv\\Lib\\site-packages\\PIL\\Image.py:972\u001b[39m, in \u001b[36mImage.convert\u001b[39m\u001b[34m(self, mode, matrix, dither, palette, colors)\u001b[39m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconvert\u001b[39m(\n\u001b[32m    921\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    922\u001b[39m     mode: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    926\u001b[39m     colors: \u001b[38;5;28mint\u001b[39m = \u001b[32m256\u001b[39m,\n\u001b[32m    927\u001b[39m ) -> Image:\n\u001b[32m    928\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    929\u001b[39m \u001b[33;03m    Returns a converted copy of this image. For the \"P\" mode, this\u001b[39;00m\n\u001b[32m    930\u001b[39m \u001b[33;03m    method translates pixels through the palette.  If mode is\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    969\u001b[39m \u001b[33;03m    :returns: An :py:class:`~PIL.Image.Image` object.\u001b[39;00m\n\u001b[32m    970\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m972\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    974\u001b[39m     has_transparency = \u001b[33m\"\u001b[39m\u001b[33mtransparency\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.info\n\u001b[32m    975\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode == \u001b[33m\"\u001b[39m\u001b[33mP\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    976\u001b[39m         \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\mscmlbead\\fruit_venv\\Lib\\site-packages\\PIL\\ImageFile.py:394\u001b[39m, in \u001b[36mImageFile.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    391\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[32m    393\u001b[39m b = b + s\n\u001b[32m--> \u001b[39m\u001b[32m394\u001b[39m n, err_code = \u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n < \u001b[32m0\u001b[39m:\n\u001b[32m    396\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# --- Trainer Function for Optuna ---\n",
    "def train_model_optuna(model, train_loader, val_loader, optimizer, criterion, epochs, device):\n",
    "    \"\"\"Simple training loop for HPO.\"\"\"\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            # FIX: labels already contains the class indices (1D tensor), no need for argmax\n",
    "            loss = criterion(outputs, labels) \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "# --- Evaluator Function for Optuna ---\n",
    "def evaluate_model_optuna(model, val_loader, device):\n",
    "    \"\"\"Simple evaluation loop for HPO.\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            # FIX: labels already contains the class indices\n",
    "            correct += (predicted == labels).sum().item() \n",
    "    return correct / total\n",
    "\n",
    "# --- Optuna Objective Function ---\n",
    "def objective(trial):\n",
    "    # Hyperparameter Search Space\n",
    "    hp_num_conv_layers = trial.suggest_int('num_conv_layers', 2, 4)\n",
    "    hp_filters = trial.suggest_categorical('filters', [32, 64, 128])\n",
    "    hp_dense_units = trial.suggest_categorical('dense_units', [128, 256, 512])\n",
    "    hp_dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.5, step=0.1)\n",
    "    hp_learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
    "\n",
    "    # Model and Setup\n",
    "    model = FruitCNN(\n",
    "        num_conv_layers=hp_num_conv_layers,\n",
    "        filters=hp_filters,\n",
    "        dense_units=hp_dense_units,\n",
    "        dropout_rate=hp_dropout_rate,\n",
    "        num_classes=NUM_CLASSES\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=hp_learning_rate)\n",
    "    \n",
    "    # Training and Evaluation\n",
    "    train_model_optuna(model, train_loader, val_loader, optimizer, criterion, NUM_EPOCHS_TUNE, DEVICE)\n",
    "    accuracy = evaluate_model_optuna(model, val_loader, DEVICE)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# --- Run Optuna Search ---\n",
    "print(\"Starting Hyperparameter Optimization (HPO) with Optuna...\")\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10) \n",
    "\n",
    "print(\"\\n--- Best Trial Results ---\")\n",
    "best_trial = study.best_trial\n",
    "print(f\"Best Validation Accuracy: {best_trial.value:.4f}\")\n",
    "print(\"Best Hyperparameters:\")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Retrieve best hyperparameters\n",
    "best_hps = best_trial.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16832e95",
   "metadata": {},
   "source": [
    "# CELL 5 - Training, Testing, Validation and Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c24d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Final Model Initialization ---\n",
    "final_model = FruitCNN(\n",
    "    num_conv_layers=best_hps['num_conv_layers'],\n",
    "    filters=best_hps['filters'],\n",
    "    dense_units=best_hps['dense_units'],\n",
    "    dropout_rate=best_hps['dropout_rate'],\n",
    "    num_classes=NUM_CLASSES\n",
    ").to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(final_model.parameters(), lr=best_hps['learning_rate'])\n",
    "\n",
    "# --- Custom Early Stopping Logic (Low-Level Logic) ---\n",
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, epochs, device, patience=10):\n",
    "    \n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_accuracy': []}\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    best_model_weights = None\n",
    "    \n",
    "    print(\"Starting Final Training with Early Stopping...\")\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            # FIX: labels already contains the class indices\n",
    "            inputs, labels = inputs.to(device), labels.to(device) \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                # FIX: labels already contains the class indices\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        val_accuracy = correct / total\n",
    "        \n",
    "        # Log History\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['val_accuracy'].append(val_accuracy)\n",
    "        \n",
    "        print(f'Epoch {epoch}/{epochs}: Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.4f}')\n",
    "        \n",
    "        # Early Stopping Logic \n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_no_improve = 0\n",
    "            # Save the best weights\n",
    "            best_model_weights = model.state_dict()\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve == patience:\n",
    "                print(f\"Early stopping at epoch {epoch}. Validation loss did not improve for {patience} epochs.\")\n",
    "                # Restore best weights\n",
    "                model.load_state_dict(best_model_weights)\n",
    "                break\n",
    "\n",
    "    return model, history\n",
    "\n",
    "# --- Run Final Training ---\n",
    "final_model, history = train_and_validate(\n",
    "    final_model, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    criterion, \n",
    "    optimizer, \n",
    "    NUM_EPOCHS_FINAL, \n",
    "    DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e59c974",
   "metadata": {},
   "source": [
    "# CELL 6 - Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df96b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model Evaluation on Test Set ---\n",
    "def evaluate_test(model, test_loader, device, class_names):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            # Labels need to be indices\n",
    "            inputs, labels = inputs.to(device), labels.to(device).argmax(dim=1)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "            \n",
    "    # Calculate Overall Accuracy Score\n",
    "    overall_accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f\"\\nOverall Test Accuracy Score: {overall_accuracy*100:.2f}%\")\n",
    "\n",
    "    # Classification Report (F-Score, Recall, Precision)\n",
    "    print(\"\\n--- Classification Report ---\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names, digits=4))\n",
    "\n",
    "    # Confusion Matrix (Visualization)\n",
    "    print(\"\\n--- Confusion Matrix ---\")\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "    \n",
    "    return overall_accuracy\n",
    "\n",
    "# --- Run Test Evaluation ---\n",
    "test_accuracy = evaluate_test(final_model, test_loader, DEVICE, CLASS_NAMES)\n",
    "\n",
    "\n",
    "# --- Plot Training History ---\n",
    "# Plot Training History (Visualization)\n",
    "def plot_history(history):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # Plot Loss\n",
    "    ax[0].plot(history['train_loss'], label='Train Loss')\n",
    "    ax[0].plot(history['val_loss'], label='Validation Loss')\n",
    "    ax[0].set_title('Training and Validation Loss')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].legend()\n",
    "\n",
    "    # Plot Accuracy\n",
    "    ax[1].plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "    ax[1].set_title('Validation Accuracy')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].set_ylabel('Accuracy')\n",
    "    ax[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n--- Training History Visualization ---\")\n",
    "plot_history(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fruit_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
